import os
import gradio as gr
from dotenv import load_dotenv
from openai import OpenAI
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

class CustomE5Embedding(HuggingFaceEmbeddings):
    """è‡ªè¨‚ E5 Embedding é¡åˆ¥ï¼ŒåŠ å…¥é©ç•¶çš„å‰ç¶´ä¾†å„ªåŒ–æª¢ç´¢æ•ˆæœ"""
    
    def embed_documents(self, texts):
        # ç‚ºæ–‡æª”åŠ ä¸Š "passage:" å‰ç¶´
        texts = [f"passage: {t}" for t in texts]
        return super().embed_documents(texts)

    def embed_query(self, text):
        # ç‚ºæŸ¥è©¢åŠ ä¸Š "query:" å‰ç¶´
        return super().embed_query(f"query: {text}")

class MathTeacherRAG:
    """ç´°å¿ƒæº«æŸ”çš„æ•¸å­¸è€å¸« RAG ç³»çµ±"""
    
    def __init__(self):
        # åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­ç½® OPENAI_API_KEY")
        
        self.client = OpenAI(api_key=api_key)
        self.retriever = None
        self.vector_db_path = "math_teacher_db"
        
        # æ•¸å­¸è€å¸«çš„äººè¨­è¨­å®š
        self.system_prompt = """ä½ æ˜¯ä¸€ä½ç´°å¿ƒæº«æŸ”çš„æ•¸å­¸è€å¸«ï¼Œæ“…é•·ç”¨ç°¡å–®æ˜“æ‡‚çš„æ–¹å¼è§£é‡‹è¤‡é›œçš„æ¦‚å¿µã€‚

ä½ çš„ç‰¹è³ªï¼š
- ç¸½æ˜¯ç”¨ ELI5 (Explain Like I'm 5) çš„æ–¹å¼ä¾†è§£é‡‹ï¼Œè®“5æ­²å°å­©éƒ½èƒ½ç†è§£
- è€å¿ƒç´°å¿ƒï¼Œå¾ä¸æ€¥èº
- æº«æŸ”è¦ªåˆ‡ï¼Œè®“å­¸ç”Ÿæ„Ÿåˆ°å®‰å¿ƒ
- å–„ç”¨æ¯”å–»å’Œç”Ÿæ´»åŒ–çš„ä¾‹å­
- æœƒé¼“å‹µå­¸ç”Ÿï¼Œè®“ä»–å€‘æœ‰ä¿¡å¿ƒ
- å¦‚æœæ¦‚å¿µè¤‡é›œï¼Œæœƒåˆ†æ­¥é©Ÿæ…¢æ…¢èªªæ˜
- ç¶“å¸¸ç¢ºèªå­¸ç”Ÿæ˜¯å¦ç†è§£

è«‹ç”¨é€™æ¨£çš„èªæ°£å’Œæ–¹å¼ä¾†å›æ‡‰å­¸ç”Ÿçš„å•é¡Œã€‚"""

        self.prompt_template = """è¦ªæ„›çš„åŒå­¸ï¼Œæ ¹æ“šæˆ‘æ‰¾åˆ°çš„æ•™æå…§å®¹ï¼š

{retrieved_content}

é‡å°ä½ çš„å•é¡Œï¼š{question}

è®“è€å¸«ç”¨æœ€ç°¡å–®çš„æ–¹å¼ä¾†ç‚ºä½ è§£é‡‹ï½"""

    def load_pdf(self, pdf_path):
        """è¼‰å…¥ PDF æª”æ¡ˆä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«"""
        try:
            print("ğŸ“š è€å¸«æ­£åœ¨è®€å–æ•™æ...")
            
            # è¼‰å…¥ PDF
            loader = PyPDFLoader(pdf_path)
            documents = loader.load()
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(documents)} é æ•™æ")
            
            # åˆ†å‰²æ–‡æª”
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,  # ç¨å¤§çš„ chunk ä¿æŒå…§å®¹å®Œæ•´æ€§
                chunk_overlap=200,  # è¶³å¤ çš„é‡ç–Šç¢ºä¿è³‡è¨Šä¸éºå¤±
                separators=["\n\n", "\n", "ã€‚", ".", " ", ""]
            )
            split_docs = text_splitter.split_documents(documents)
            print(f"ğŸ“„ å°‡æ•™æåˆ†æˆ {len(split_docs)} å€‹å°æ®µè½")
            
            # å»ºç«‹å‘é‡è³‡æ–™åº«
            print("ğŸ§  æ­£åœ¨å»ºç«‹çŸ¥è­˜ç´¢å¼•...")
            embedding_model = CustomE5Embedding(
                model_name="intfloat/multilingual-e5-small"
            )
            
            vectorstore = FAISS.from_documents(split_docs, embedding_model)
            
            # å„²å­˜å‘é‡è³‡æ–™åº«
            vectorstore.save_local(self.vector_db_path)
            print("ğŸ’¾ çŸ¥è­˜ç´¢å¼•å»ºç«‹å®Œæˆï¼")
            
            # è¨­å®šæª¢ç´¢å™¨
            self.retriever = vectorstore.as_retriever(
                search_kwargs={"k": 4}  # æª¢ç´¢æœ€ç›¸é—œçš„4å€‹æ®µè½
            )
            
            return True, "ğŸ“š æ•™æè¼‰å…¥æˆåŠŸï¼è€å¸«å·²ç¶“æº–å‚™å¥½å›ç­”ä½ çš„å•é¡Œäº†ï½"
            
        except Exception as e:
            error_msg = f"ğŸ˜… æŠ±æ­‰ï¼Œè¼‰å…¥æ•™ææ™‚é‡åˆ°äº†å•é¡Œï¼š{str(e)}"
            print(error_msg)
            return False, error_msg

    def load_existing_db(self):
        """è¼‰å…¥å·²å­˜åœ¨çš„å‘é‡è³‡æ–™åº«"""
        try:
            if os.path.exists(self.vector_db_path):
                print("ğŸ“– æ‰¾åˆ°å·²å»ºç«‹çš„çŸ¥è­˜ç´¢å¼•ï¼Œæ­£åœ¨è¼‰å…¥...")
                embedding_model = CustomE5Embedding(
                    model_name="intfloat/multilingual-e5-small"
                )
                vectorstore = FAISS.load_local(
                    self.vector_db_path, 
                    embedding_model, 
                    allow_dangerous_deserialization=True
                )
                self.retriever = vectorstore.as_retriever(
                    search_kwargs={"k": 4}
                )
                print("âœ… çŸ¥è­˜ç´¢å¼•è¼‰å…¥æˆåŠŸï¼")
                return True
            return False
        except Exception as e:
            print(f"âš ï¸ è¼‰å…¥çŸ¥è­˜ç´¢å¼•æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
            return False

    def answer_question(self, question):
        """å›ç­”å­¸ç”Ÿå•é¡Œ"""
        if not self.retriever:
            return "ğŸ˜Š è€å¸«é‚„æ²’æœ‰è¼‰å…¥æ•™æå“¦ï¼è«‹å…ˆä¸Šå‚³ PDF æª”æ¡ˆï½"
        
        if not question.strip():
            return "ğŸ’­ è¦ªæ„›çš„åŒå­¸ï¼Œè«‹å‘Šè¨´è€å¸«ä½ æƒ³å•ä»€éº¼å•é¡Œå‘¢ï¼Ÿ"
        
        try:
            # æª¢ç´¢ç›¸é—œå…§å®¹
            docs = self.retriever.get_relevant_documents(question)
            retrieved_content = "\n\n".join([doc.page_content for doc in docs])
            
            # å»ºç«‹å®Œæ•´çš„ prompt
            full_prompt = self.prompt_template.format(
                retrieved_content=retrieved_content,
                question=question
            )
            
            # å‘¼å« OpenAI API
            response = self.client.chat.completions.create(
                model="gpt-4o",  # ä½¿ç”¨è¼ƒå¥½çš„æ¨¡å‹ä¾†ç¢ºä¿å›ç­”å“è³ª
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": full_prompt}
                ],
                temperature=0.7,  # ç¨å¾®å¢åŠ å‰µæ„æ€§ï¼Œè®“è§£é‡‹æ›´ç”Ÿå‹•
                max_tokens=1500   # ç¢ºä¿æœ‰è¶³å¤ ç©ºé–“è©³ç´°è§£é‡‹
            )
            
            answer = response.choices[0].message.content
            return answer
            
        except Exception as e:
            return f"ğŸ˜… æŠ±æ­‰ï¼Œè€å¸«åœ¨æ€è€ƒç­”æ¡ˆæ™‚é‡åˆ°äº†ä¸€é»å•é¡Œï¼š{str(e)}\nè«‹å†è©¦ä¸€æ¬¡ï¼Œæˆ–è€…ç”¨ä¸åŒçš„æ–¹å¼å•å•é¡Œå“¦ï½"

def create_gradio_interface():
    """å»ºç«‹ Gradio ä»‹é¢"""
    
    # åˆå§‹åŒ– RAG ç³»çµ±
    math_teacher = MathTeacherRAG()
    
    # å˜—è©¦è¼‰å…¥å·²å­˜åœ¨çš„è³‡æ–™åº«
    if math_teacher.load_existing_db():
        initial_message = "ğŸ“š è€å¸«å·²ç¶“æº–å‚™å¥½äº†ï¼æœ‰ä»€éº¼æ•¸å­¸å•é¡Œæƒ³å•è€å¸«å—ï¼Ÿ"
    else:
        initial_message = "ğŸ‘‹ è¦ªæ„›çš„åŒå­¸ä½ å¥½ï¼è€å¸«éœ€è¦å…ˆè¼‰å…¥æ•™ææ‰èƒ½å›ç­”å•é¡Œå“¦ï½"
    
    def upload_and_process_pdf(pdf_file):
        """è™•ç† PDF ä¸Šå‚³"""
        if pdf_file is None:
            return "ğŸ“ è«‹é¸æ“‡ä¸€å€‹ PDF æª”æ¡ˆä¸Šå‚³çµ¦è€å¸«ï½"
        
        success, message = math_teacher.load_pdf(pdf_file.name)
        return message
    
    def chat_with_teacher(message, history):
        """èˆ‡æ•¸å­¸è€å¸«å°è©±"""
        if not message.strip():
            return history, ""
        
        # ç²å¾—è€å¸«çš„å›ç­”
        teacher_response = math_teacher.answer_question(message)
        
        # æ›´æ–°å°è©±æ­·å²
        history.append([message, teacher_response])
        
        return history, ""
    
    # å»ºç«‹ Gradio ä»‹é¢
    with gr.Blocks(
        title="æº«æŸ”æ•¸å­¸è€å¸«", 
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            max-width: 800px !important;
            margin: auto !important;
        }
        """
    ) as demo:
        
        gr.Markdown("""
        # ğŸ§® æº«æŸ”çš„æ•¸å­¸è€å¸«
        
        ### ğŸ‘©â€ğŸ« å—¨ï¼æˆ‘æ˜¯ä½ çš„æ•¸å­¸è€å¸«
        æˆ‘æœƒç”¨æœ€ç°¡å–®ã€æœ€æº«æŸ”çš„æ–¹å¼ä¾†è§£é‡‹æ•¸å­¸æ¦‚å¿µï¼Œå°±åƒå°5æ­²å°æœ‹å‹èªªè©±ä¸€æ¨£ï½
        
        **ä½¿ç”¨æ–¹æ³•ï¼š**
        1. ğŸ“¤ å…ˆä¸Šå‚³ä½ çš„æ•¸å­¸æ•™æ (PDFæª”æ¡ˆ)
        2. ğŸ’¬ ç„¶å¾Œå°±å¯ä»¥å•è€å¸«ä»»ä½•æ•¸å­¸å•é¡Œäº†ï¼
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                pdf_upload = gr.File(
                    label="ğŸ“š ä¸Šå‚³æ•¸å­¸æ•™æ (PDF)",
                    file_types=[".pdf"],
                    type="filepath"
                )
                upload_status = gr.Textbox(
                    label="ğŸ“‹ ä¸Šå‚³ç‹€æ…‹",
                    value=initial_message,
                    interactive=False,
                    lines=2
                )
        
        with gr.Row():
            with gr.Column():
                chatbot = gr.Chatbot(
                    label="ğŸ’¬ èˆ‡æ•¸å­¸è€å¸«å°è©±",
                    height=400,
                    placeholder="è€å¸«æœƒåœ¨é€™è£¡å›ç­”ä½ çš„å•é¡Œï½",
                    show_label=True
                )
                
                with gr.Row():
                    msg_input = gr.Textbox(
                        label="",
                        placeholder="æœ‰ä»€éº¼æ•¸å­¸å•é¡Œæƒ³å•è€å¸«å‘¢ï¼Ÿ (ä¾‹å¦‚ï¼šä»€éº¼æ˜¯åˆ†æ•¸ï¼Ÿ)",
                        lines=2,
                        scale=4
                    )
                    send_btn = gr.Button("ğŸš€ ç™¼é€", scale=1, variant="primary")
        
        gr.Markdown("""
        ### ğŸ’¡ å°æç¤º
        - å¯ä»¥å•æ¦‚å¿µè§£é‡‹ï¼šã€Œä»€éº¼æ˜¯äºŒæ¬¡æ–¹ç¨‹å¼ï¼Ÿã€
        - å¯ä»¥å•è§£é¡Œæ–¹æ³•ï¼šã€Œå¦‚ä½•è§£é€™å€‹æ–¹ç¨‹å¼ï¼Ÿã€
        - å¯ä»¥å•æ‡‰ç”¨å•é¡Œï¼šã€Œé€™å€‹æ¦‚å¿µåœ¨ç”Ÿæ´»ä¸­æ€éº¼ç”¨ï¼Ÿã€
        - è€å¸«æœƒç”¨æœ€ç°¡å–®çš„æ–¹å¼è§£é‡‹ï¼Œä¸æ‡‚å¯ä»¥ç¹¼çºŒå•å“¦ï¼
        """)
        
        # äº‹ä»¶ç¶å®š
        pdf_upload.change(
            fn=upload_and_process_pdf,
            inputs=[pdf_upload],
            outputs=[upload_status]
        )
        
        msg_input.submit(
            fn=chat_with_teacher,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, msg_input]
        )
        
        send_btn.click(
            fn=chat_with_teacher,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, msg_input]
        )
    
    return demo

if __name__ == "__main__":
    # æª¢æŸ¥å¿…è¦å¥—ä»¶ - ä½¿ç”¨æ­£ç¢ºçš„æ¨¡çµ„åç¨±
    package_check_map = {
        "gradio": "gradio",
        "openai": "openai", 
        "python-dotenv": "dotenv",  # å¥—ä»¶å vs æ¨¡çµ„åä¸åŒ
        "langchain": "langchain",
        "langchain-community": "langchain_community",
        "sentence-transformers": "sentence_transformers",
        "faiss-cpu": "faiss",  # å¥—ä»¶å vs æ¨¡çµ„åä¸åŒ
        "pypdf": "pypdf"
    }
    
    print("ğŸ” æª¢æŸ¥å¿…è¦å¥—ä»¶...")
    missing_packages = []
    
    for package_name, module_name in package_check_map.items():
        try:
            __import__(module_name)
        except ImportError:
            missing_packages.append(package_name)
    
    if missing_packages:
        print(f"âŒ ç¼ºå°‘ä»¥ä¸‹å¥—ä»¶ï¼Œè«‹åŸ·è¡Œï¼š")
        print(f"pip install {' '.join(missing_packages)}")
        exit(1)
    
    print("âœ… æ‰€æœ‰å¥—ä»¶éƒ½å·²å®‰è£ï¼")
    
    # æª¢æŸ¥ .env æª”æ¡ˆ
    if not os.path.exists('.env'):
        print("âš ï¸ æ‰¾ä¸åˆ° .env æª”æ¡ˆï¼Œè«‹å»ºç«‹ .env ä¸¦åŠ å…¥ï¼š")
        print("OPENAI_API_KEY=your_api_key_here")
        exit(1)
    
    # å•Ÿå‹•æ‡‰ç”¨
    print("ğŸš€ å•Ÿå‹•æº«æŸ”æ•¸å­¸è€å¸«...")
    demo = create_gradio_interface()
    demo.launch(
        share=True,  # ç”¢ç”Ÿå…¬é–‹é€£çµ
        server_name="0.0.0.0",  # å…è¨±å¤–éƒ¨å­˜å–
        server_port=7860,  # æŒ‡å®š port
        show_error=True  # é¡¯ç¤ºéŒ¯èª¤è³‡è¨Š
    )