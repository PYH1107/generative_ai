import gradio as gr
from openai import OpenAI  # æ–°ç‰ˆæœ¬çš„å°å…¥æ–¹å¼
import requests
import json
import os
import time
from typing import List, Tuple
from dotenv import load_dotenv
from groq import Groq
load_dotenv()

# è¨­ç½® API å¯†é‘° - æ–°ç‰ˆæœ¬çš„æ–¹å¼
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
groq_client = Groq(api_key=os.getenv("GROQ_API_KEY"))

class AICharacter:
    def __init__(self, name: str, personality: str, model_type: str):
        self.name = name
        self.personality = personality
        self.model_type = model_type
        self.conversation_history = []

# å®šç¾©å…©å€‹å°–é…¸åˆ»è–„çš„è§’è‰²
character_a = AICharacter(
    name="æ¯’èˆŒè©•è«–å®¶è‰¾è‰çµ²",
    personality="""ä½ æ˜¯ä¸€å€‹æ¥µå…¶å°–é…¸åˆ»è–„çš„è—è¡“è©•è«–å®¶ï¼Œåå«è‰¾è‰çµ²ã€‚ä½ çš„ç‰¹é»ï¼š
    - ç¸½æ˜¯ç”¨æœ€æŒ‘å‰”çš„çœ¼å…‰çœ‹å¾…ä¸€åˆ‡
    - èªªè©±å°–éŠ³ï¼Œå–œæ­¡æŒ–è‹¦è«·åˆº
    - èªç‚ºè‡ªå·±å“å‘³é«˜é›…ï¼Œçœ‹ä¸èµ·åº¸ä¿—çš„æ±è¥¿
    - ç¶“å¸¸ä½¿ç”¨åè«·å’ŒæŒ–è‹¦çš„èªèª¿
    - å–œæ­¡å¼•ç”¨ä¸€äº›æ™¦æ¾€çš„æ–‡å­¸æˆ–è—è¡“å…¸æ•…ä¾†é¡¯ç¤ºè‡ªå·±çš„å­¸è­˜
    è«‹ä¿æŒé€™å€‹äººè¨­ï¼Œç”¨å°–é…¸åˆ»è–„ä½†ä¸å¤±æ©Ÿæ™ºçš„æ–¹å¼å›æ‡‰å°æ–¹ã€‚""",
    model_type="openai"
)

character_b = AICharacter(
    name="æ¯’å˜´å“²å­¸å®¶åšå£«",
    personality="""ä½ æ˜¯ä¸€å€‹æ†¤ä¸–å«‰ä¿—çš„å“²å­¸å®¶ï¼Œåå«åšå£«ã€‚ä½ çš„ç‰¹é»ï¼š
    - å°ç¾ä»£ç¤¾æœƒå’Œäººæ€§æ¥µåº¦æ‚²è§€
    - èªªè©±çŠ€åˆ©ï¼Œå–œæ­¡æˆ³ç©¿è™›å½
    - ç¶“å¸¸å¼•ç”¨å°¼é‡‡ã€å”æœ¬è¯ç­‰æ‚²è§€ä¸»ç¾©å“²å­¸å®¶çš„è§€é»
    - ç”¨ç†æ€§çš„å¤–è¡£åŒ…è£å°–åˆ»çš„æ‰¹è©•
    - å–œæ­¡è³ªç–‘ä¸€åˆ‡ï¼ŒåŒ…æ‹¬å°æ–¹çš„è§€é»
    è«‹ä¿æŒé€™å€‹äººè¨­ï¼Œç”¨å“²å­¸å¼çš„æ¯’èˆŒæ–¹å¼å›æ‡‰å°æ–¹ã€‚""",
    model_type="groq"
)

def call_openai_api(messages: List[dict]) -> str:
    """èª¿ç”¨ OpenAI API - ä½¿ç”¨æ–°ç‰ˆæœ¬æ ¼å¼"""
    try:
        response = openai_client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            max_tokens=300,
            temperature=0.8
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"OpenAI API éŒ¯èª¤: {str(e)}"

def call_groq_api(messages: List[dict]) -> str:
    """ä½¿ç”¨ Groq SDK èª¿ç”¨ Llama3 æ¨¡å‹"""
    try:
        response = groq_client.chat.completions.create(
            model="llama3-70b-8192",  # Groq æä¾›çš„é«˜é€Ÿæ¨¡å‹
            messages=messages,
            temperature=0.8,
            max_tokens=300
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"Grok API éŒ¯èª¤: {str(e)}"


def test_openai_connection() -> bool:
    """æ¸¬è©¦ OpenAI API é€£æ¥"""
    try:
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",  # ä½¿ç”¨è¼ƒä¾¿å®œçš„æ¨¡å‹æ¸¬è©¦
            messages=[{"role": "user", "content": "æ¸¬è©¦"}],
            max_tokens=5
        )
        if response.choices[0].message.content:
            print("âœ… OpenAI API é€£æ¥æ­£å¸¸")
            return True
    except Exception as e:
        print(f"âŒ OpenAI API æ¸¬è©¦å¤±æ•—: {str(e)}")
        return False

def test_groq_connection() -> bool:
    """æ¸¬è©¦ Groq API é€£æ¥"""
    try:
        groq_key = os.getenv("GROQ_API_KEY")
        headers = {
            "Authorization": f"Bearer {groq_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "messages": [{"role": "user", "content": "æ¸¬è©¦"}],
            "model": "llama3-70b-8192",
            "max_tokens": 5
        }
        
        response = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=10
        )
        
        if response.status_code == 200:
            print("âœ… Groq API é€£æ¥æ­£å¸¸")
            return True
        else:
            print(f"âŒ Groq API æ¸¬è©¦å¤±æ•—: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        print(f"âŒ Groq API æ¸¬è©¦å¤±æ•—: {str(e)}")
        return False


def get_ai_response(character: AICharacter, conversation_context: str) -> str:
    """ç²å– AI è§’è‰²çš„å›æ‡‰"""
    messages = [
        {"role": "system", "content": character.personality},
        {"role": "user", "content": f"å°è©±æƒ…å¢ƒï¼š{conversation_context}\nè«‹ä»¥{character.name}çš„èº«ä»½å›æ‡‰ã€‚"}
    ]
    
    if character.model_type == "openai":
        return call_openai_api(messages)
    else:
        return call_groq_api(messages)

def start_conversation(topic: str, rounds: int) -> List[Tuple[str, str]]:
    """é–‹å§‹å°è©±"""
    conversation = []
    current_topic = topic
    
    for round_num in range(rounds):
        # è‰¾è‰çµ² (OpenAI) å…ˆèªª
        if round_num == 0:
            context = f"è©±é¡Œï¼š{topic}ã€‚è«‹é–‹å§‹é€™å€‹è©±é¡Œçš„è¨è«–ã€‚"
        else:
            context = f"è©±é¡Œï¼š{topic}ã€‚å°æ–¹å‰›æ‰èªªï¼š'{conversation[-1][1]}'ã€‚è«‹å›æ‡‰ã€‚"
        
        alice_response = get_ai_response(character_a, context)
        
        # åšå£« (Groq) å›æ‡‰
        context = f"è©±é¡Œï¼š{topic}ã€‚å°æ–¹({character_a.name})å‰›æ‰èªªï¼š'{alice_response}'ã€‚è«‹å›æ‡‰ã€‚"
        doctor_response = get_ai_response(character_b, context)
        
        conversation.append((
            f"ğŸ­ {character_a.name}: {alice_response}",
            f"ğŸ§  {character_b.name}: {doctor_response}"
        ))
        
        # æ·»åŠ å»¶é²é¿å… API é™åˆ¶
        time.sleep(1)
    
    return conversation

def format_conversation(conversation: List[Tuple[str, str]]) -> str:
    """æ ¼å¼åŒ–å°è©±çµæœ"""
    formatted = "=== ğŸ”¥ æ¯’èˆŒé›™é›„å°è©±å¯¦éŒ„ ğŸ”¥ ===\n\n"
    
    for i, (alice_msg, doctor_msg) in enumerate(conversation, 1):
        formatted += f"ã€ç¬¬ {i} å›åˆã€‘\n"
        formatted += f"{alice_msg}\n\n"
        formatted += f"{doctor_msg}\n\n"
        formatted += "â”€" * 50 + "\n\n"
    
    return formatted

def gradio_interface(topic: str, rounds: int) -> str:
    """Gradio ä»‹é¢å‡½æ•¸"""
    if not topic.strip():
        return "âŒ è«‹è¼¸å…¥å°è©±è©±é¡Œï¼"
    
    if rounds < 1 or rounds > 10:
        return "âŒ å°è©±å›åˆæ•¸è«‹è¨­ç½®åœ¨ 1-10 ä¹‹é–“ï¼"
    
    try:
        conversation = start_conversation(topic, rounds)
        return format_conversation(conversation)
    except Exception as e:
        return f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"

# å‰µå»º Gradio ä»‹é¢
with gr.Blocks(
    theme="soft",
    title="ğŸ”¥ æ¯’èˆŒé›™é›„å°è©±æ©Ÿå™¨äºº",
    css="""
    .gradio-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    .gr-button {
        background: linear-gradient(45deg, #ff6b6b, #ee5a52);
        border: none;
        color: white;
        font-weight: bold;
    }
    .gr-textbox {
        border-radius: 10px;
    }
    """
) as app:
    
    gr.Markdown("""
    # ğŸ”¥ æ¯’èˆŒé›™é›„å°è©±æ©Ÿå™¨äºº ğŸ”¥
    
    è®“å…©å€‹æ¥µå…¶å°–é…¸åˆ»è–„çš„ AI è§’è‰²äº’ç›¸å°è©±ï¼
    
    **ğŸ­ æ¯’èˆŒè©•è«–å®¶è‰¾è‰çµ²** (GPT-4) VS **ğŸ§  æ¯’å˜´å“²å­¸å®¶åšå£«** (Groq)
    
    ---
    """)
    
    with gr.Row():
        with gr.Column(scale=2):
            topic_input = gr.Textbox(
                label="ğŸ’¬ å°è©±è©±é¡Œ",
                placeholder="ä¾‹å¦‚ï¼šç¾ä»£è—è¡“çš„åƒ¹å€¼ã€ç¤¾äº¤åª’é«”çš„å½±éŸ¿ã€äººå·¥æ™ºèƒ½çš„æœªä¾†...",
                lines=2
            )
            
            rounds_input = gr.Slider(
                minimum=1,
                maximum=10,
                value=3,
                step=1,
                label="ğŸ”„ å°è©±å›åˆæ•¸"
            )
            
            start_button = gr.Button(
                "ğŸš€ é–‹å§‹æ¯’èˆŒå°è©±",
                variant="primary",
                size="lg"
            )
        
        with gr.Column(scale=1):
            gr.Markdown("""
            ### ğŸ“‹ ä½¿ç”¨èªªæ˜
            
            1. **è¼¸å…¥è©±é¡Œ**ï¼šä»»ä½•ä½ æƒ³è®“ä»–å€‘è¨è«–çš„è©±é¡Œ
            2. **è¨­ç½®å›åˆæ•¸**ï¼šå»ºè­°3-5å›åˆ
            3. **é»æ“Šé–‹å§‹**ï¼šåç­‰ç²¾å½©çš„æ¯’èˆŒå°æˆ°
            
            ### ğŸ­ è§’è‰²ä»‹ç´¹
            
            **è‰¾è‰çµ²**ï¼šå°–é…¸åˆ»è–„çš„è—è¡“è©•è«–å®¶  
            **åšå£«**ï¼šæ†¤ä¸–å«‰ä¿—çš„å“²å­¸å®¶
            
            ---
            *âš ï¸ æ³¨æ„ï¼šå°è©±å…§å®¹ç´”å±¬è™›æ§‹ï¼Œè«‹å‹¿ç•¶çœŸï¼*
            """)
    
    output_text = gr.Textbox(
        label="ğŸª å°è©±çµæœ",
        lines=20,
        max_lines=30,
        show_copy_button=True
    )
    
    start_button.click(
        fn=gradio_interface,
        inputs=[topic_input, rounds_input],
        outputs=output_text
    )
    
    gr.Markdown("""
    ---
    ### ğŸ”§ æŠ€è¡“èªªæ˜
    - **OpenAI GPT-4**ï¼šé©…å‹•æ¯’èˆŒè©•è«–å®¶è‰¾è‰çµ²
    - **Groq AI**ï¼šé©…å‹•æ¯’å˜´å“²å­¸å®¶åšå£«
    - **Gradio**ï¼šæä¾›äº’å‹•ä»‹é¢
    
    *Made with ğŸ’€ and a bit of sass*
    """)

if __name__ == "__main__":
    print("ğŸ” æª¢æŸ¥ç’°å¢ƒè®Šæ•¸...")
    
    # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    openai_key = os.getenv("OPENAI_API_KEY")
    groq_key = os.getenv("GROQ_API_KEY")
    
    if not openai_key:
        print("âŒ è«‹è¨­ç½® OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")
        print("   æ ¼å¼ï¼šexport OPENAI_API_KEY='sk-proj-...'")
    else:
        print(f"âœ… OpenAI API Key å·²è¨­ç½® (å‰ç¶´: {openai_key[:20]}...)")
    
    if not groq_key:
        print("âŒ è«‹è¨­ç½® GROQ_API_KEY ç’°å¢ƒè®Šæ•¸") 
        print("   æ ¼å¼ï¼šexport GROQ_API_KEY='gsk_...'")
    else:
        print(f"âœ… Groq API Key å·²è¨­ç½® (å‰ç¶´: {groq_key[:10]}...)")
    
    if not openai_key or not groq_key:
        print("\nè«‹å…ˆè¨­ç½®å¥½ API å¯†é‘°å†é‡æ–°é‹è¡Œç¨‹åº")
        exit(1)
    
    print("\nğŸ§ª æ¸¬è©¦ API é€£æ¥...")
    openai_ok = test_openai_connection()
    groq_ok = test_groq_connection()
    
    if not openai_ok or not groq_ok:
        print("\nâš ï¸  è­¦å‘Šï¼šéƒ¨åˆ† API ç„¡æ³•é€£æ¥ï¼Œç¨‹åºä»æœƒå•Ÿå‹•ä½†å¯èƒ½ç„¡æ³•æ­£å¸¸å·¥ä½œ")
        print("è«‹æª¢æŸ¥ API å¯†é‘°è¨­ç½®å’Œç¶²çµ¡é€£æ¥")
    else:
        print("\nğŸ‰ æ‰€æœ‰ API é€£æ¥æ­£å¸¸ï¼")
    
    print("\nğŸš€ å•Ÿå‹•æ¯’èˆŒé›™é›„å°è©±æ©Ÿå™¨äºº...")
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        debug=True
    )