{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLsw447fynsyL8ZLe1PzjV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PYH1107/generative_ai/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGFYc-DOW7hg"
      },
      "outputs": [],
      "source": [
        "# ========== Cell 1: è§£æ±ºä¾è³´è¡çªä¸¦å®‰è£å¿…è¦å¥—ä»¶ ==========\n",
        "print(\"ğŸ”§ æ­£åœ¨è§£æ±ºä¾è³´è¡çªä¸¦å®‰è£å¥—ä»¶...\")\n",
        "\n",
        "# Step 1: é‡æ–°å®‰è£ç›¸å®¹çš„ PyTorch ç”Ÿæ…‹ç³»çµ±\n",
        "!pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124\n",
        "\n",
        "# Step 2: å®‰è£å…¶ä»– AI ç›¸é—œå¥—ä»¶ï¼ˆæŒ‡å®šç›¸å®¹ç‰ˆæœ¬ï¼‰\n",
        "!pip install transformers==4.44.0 accelerate==0.34.0 safetensors==0.4.5\n",
        "\n",
        "# Step 3: å®‰è£ diffusersï¼ˆä½¿ç”¨ç›¸å®¹ç‰ˆæœ¬ï¼‰\n",
        "!pip install diffusers==0.30.0\n",
        "\n",
        "# Step 4: å®‰è£ Gradio\n",
        "!pip install gradio==4.44.0\n",
        "\n",
        "# Step 5: å®‰è£ aisuiteï¼ˆåªå®‰è£éœ€è¦çš„ providerï¼‰\n",
        "!pip install groq==0.9.0 openai==1.35.8\n",
        "\n",
        "# Step 6: å®‰è£ HuggingFace Hub\n",
        "!pip install huggingface_hub==0.25.0\n",
        "\n",
        "print(\"âœ… å¥—ä»¶å®‰è£å®Œæˆï¼å¦‚æœé‚„æœ‰éŒ¯èª¤ï¼Œè«‹é‡å•Ÿ Runtime å¾Œé‡æ–°åŸ·è¡Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Cell 2: å°å…¥å¿…è¦åº«å’Œç°¡åŒ–ç‰ˆ AI å®¢æˆ¶ç«¯ ==========\n",
        "import torch\n",
        "import gc\n",
        "import random\n",
        "import gradio as gr\n",
        "from diffusers import StableDiffusionPipeline, UniPCMultistepScheduler\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata\n",
        "print(\"âœ… æ‰€æœ‰åº«å°å…¥æˆåŠŸï¼\")\n",
        "\n",
        "# ç°¡åŒ–ç‰ˆ AI å®¢æˆ¶ç«¯ï¼ˆé¿å… aisuite ä¾è³´å•é¡Œï¼‰\n",
        "class SimpleAIClient:\n",
        "    def __init__(self, provider=\"groq\", api_key=None):\n",
        "        self.provider = provider\n",
        "        self.api_key = api_key\n",
        "\n",
        "        if provider == \"groq\":\n",
        "            self.base_url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "            self.model = \"llama3-70b-8192\"\n",
        "        elif provider == \"openai\":\n",
        "            self.base_url = \"https://api.openai.com/v1/chat/completions\"\n",
        "            self.model = \"gpt-4o-mini\"\n",
        "\n",
        "    def get_response(self, messages):\n",
        "        \"\"\"ç²å– AI å›æ‡‰\"\"\"\n",
        "        try:\n",
        "            headers = {\n",
        "                \"Authorization\": f\"Bearer {self.api_key}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            }\n",
        "\n",
        "            data = {\n",
        "                \"model\": self.model,\n",
        "                \"messages\": messages,\n",
        "                \"temperature\": 0.7,\n",
        "                \"max_tokens\": 500\n",
        "            }\n",
        "\n",
        "            response = requests.post(self.base_url, headers=headers, json=data, timeout=30)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                return result[\"choices\"][0][\"message\"][\"content\"]\n",
        "            else:\n",
        "                return f\"API éŒ¯èª¤: {response.status_code} - {response.text}\"\n",
        "\n",
        "        except requests.exceptions.Timeout:\n",
        "            return \"è«‹æ±‚è¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦\"\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            return f\"é€£æ¥éŒ¯èª¤: {str(e)}\"\n",
        "        except Exception as e:\n",
        "            return f\"æœªçŸ¥éŒ¯èª¤: {str(e)}\"\n",
        "\n",
        "print(\"ğŸ¤– ç°¡åŒ–ç‰ˆ AI å®¢æˆ¶ç«¯å°±ç·’ï¼\")\n"
      ],
      "metadata": {
        "id": "kvE3FYgXYC_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Cell 3: API é‡‘é‘°è¨­å®š ==========\n",
        "# è¨­å®š AI Agent çš„ API\n",
        "try:\n",
        "    api_key = userdata.get('groq')\n",
        "    ai_client = SimpleAIClient(provider=\"groq\", api_key=api_key)\n",
        "    print(\"ğŸ”‘ ä½¿ç”¨ Groq API\")\n",
        "except:\n",
        "    print(\"âŒ æœªæ‰¾åˆ° Groq API Key\")"
      ],
      "metadata": {
        "id": "Lk8GK7rsYtay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Cell 4: æª¢æ¸¬ç’°å¢ƒä¸¦åŠ è¼‰ SD æ¨¡å‹ ==========\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"ğŸ–¥ï¸ æª¢æ¸¬åˆ°è¨­å‚™: {device}\")\n",
        "\n",
        "# åŠ è¼‰ Stable Diffusion æ¨¡å‹\n",
        "try:\n",
        "    model_name = \"runwayml/stable-diffusion-v1-5\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "        use_safetensors=True\n",
        "    ).to(device)\n",
        "\n",
        "    pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "    if device == \"cpu\":\n",
        "        pipe.enable_attention_slicing()\n",
        "        print(\"CPU æ¨¡å¼ï¼šå·²å•Ÿç”¨æœ€ä½³åŒ–\")\n",
        "    else:\n",
        "        pipe.enable_model_cpu_offload()\n",
        "        print(\"GPU æ¨¡å¼ï¼šå·²å•Ÿç”¨è¨˜æ†¶é«”æœ€ä½³åŒ–\")\n",
        "\n",
        "    print(\"âœ… Stable Diffusion æ¨¡å‹è¼‰å…¥æˆåŠŸï¼\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}\")\n"
      ],
      "metadata": {
        "id": "tiOQ9PO-Y3Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Cell 5: AI Agent ç³»çµ±è¨­è¨ˆ ==========\n",
        "class DiaryAgent:\n",
        "    def __init__(self, ai_client):\n",
        "        self.ai_client = ai_client\n",
        "        self.conversation_history = []\n",
        "        self.user_responses = []\n",
        "\n",
        "        # é è¨­çš„å•é¡Œåºåˆ—\n",
        "        self.questions = [\n",
        "            \"å—¨ï¼ä»Šå¤©æƒ³å’Œæˆ‘èŠèŠå—ï¼Ÿå…ˆå‘Šè¨´æˆ‘ï¼Œä»Šå¤©ä½ çš„å¿ƒæƒ…å¦‚ä½•å‘¢ï¼ŸğŸ˜Š\",\n",
        "            \"è½èµ·ä¾†å¾ˆæ£’ï¼é‚£ä»Šå¤©æœ‰ç™¼ç”Ÿä»€éº¼ç‰¹åˆ¥çš„äº‹æƒ…å—ï¼Ÿå¯ä»¥æ˜¯é–‹å¿ƒçš„ã€æœ‰è¶£çš„ï¼Œæˆ–æ˜¯è®“ä½ å°è±¡æ·±åˆ»çš„äº‹ âœ¨\",\n",
        "            \"çœŸæœ‰æ„æ€ï¼å¦‚æœè¦ç”¨ä¸€å€‹é¡è‰²ä¾†å½¢å®¹ç¾åœ¨çš„ä½ ï¼Œä½ æœƒé¸ä»€éº¼é¡è‰²ï¼Ÿç‚ºä»€éº¼å‘¢ï¼ŸğŸ¨\",\n",
        "            \"å¥½æ£’çš„é¸æ“‡ï¼é‚£ä½ è¦ºå¾—ç¾åœ¨çš„è‡ªå·±æ›´åƒæ˜¯ä»€éº¼ï¼Ÿæ¯”å¦‚ä¸€éš»å‹•ç‰©ã€ä¸€ç¨®æ¤ç‰©ï¼Œæˆ–æ˜¯ä»»ä½•ä½ æƒ³åˆ°çš„æ±è¥¿ï¼ŸğŸŒŸ\",\n",
        "            \"æœ€å¾Œä¸€å€‹å•é¡Œå›‰ï½å¦‚æœæˆ‘è¦ç•«ä¸€å¹…ç•«ä¾†å±•ç¾ä»Šå¤©çš„ä½ ï¼Œä½ å¸Œæœ›è‡ªå·±åœ¨ç•«ä¸­æ˜¯ä»€éº¼æ¨£å­ï¼Ÿåœ¨åšä»€éº¼å‘¢ï¼ŸğŸ–¼ï¸\"\n",
        "        ]\n",
        "\n",
        "        self.current_question_index = 0\n",
        "\n",
        "    def get_ai_response(self, system_prompt, user_input):\n",
        "        \"\"\"ç²å– AI å›æ‡‰\"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]\n",
        "\n",
        "        return self.ai_client.get_response(messages)\n",
        "\n",
        "    def get_next_question(self):\n",
        "        \"\"\"ç²å–ä¸‹ä¸€å€‹å•é¡Œ\"\"\"\n",
        "        if self.current_question_index < len(self.questions):\n",
        "            question = self.questions[self.current_question_index]\n",
        "            self.current_question_index += 1\n",
        "            return question, False  # False è¡¨ç¤ºå°è©±æœªçµæŸ\n",
        "        else:\n",
        "            return \"è¬è¬ä½ å’Œæˆ‘åˆ†äº«é€™éº¼å¤šï¼ç¾åœ¨è®“æˆ‘ç‚ºä½ å‰µä½œä¸€å¹…å°ˆå±¬çš„ç•«åƒå§ ğŸ¨âœ¨\", True  # True è¡¨ç¤ºå°è©±çµæŸ\n",
        "\n",
        "    def process_user_response(self, user_input):\n",
        "        \"\"\"è™•ç†ç”¨æˆ¶å›æ‡‰ä¸¦ç”Ÿæˆé©ç•¶çš„è·Ÿé€²\"\"\"\n",
        "        if self.current_question_index == 0:\n",
        "            # ç¬¬ä¸€å€‹å•é¡Œçš„å›æ‡‰\n",
        "            system_prompt = \"\"\"ä½ æ˜¯ä¸€ä½æº«æš–è²¼å¿ƒçš„æœ‹å‹ï¼Œå–„æ–¼å‚¾è½å’Œé¼“å‹µã€‚ç”¨æˆ¶å‰›å‰›åˆ†äº«äº†ä»–å€‘ä»Šå¤©çš„å¿ƒæƒ…ï¼Œè«‹çµ¦å‡º 1-2 å¥æº«æš–çš„å›æ‡‰ï¼Œç„¶å¾Œè‡ªç„¶åœ°å¼•å°åˆ°ä¸‹ä¸€å€‹è©±é¡Œã€‚ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œèªèª¿è¦ªåˆ‡è‡ªç„¶ã€‚\"\"\"\n",
        "        elif self.current_question_index == 1:\n",
        "            # é‡å°ä»Šå¤©ç™¼ç”Ÿçš„äº‹çš„å›æ‡‰\n",
        "            system_prompt = \"\"\"ä½ æ˜¯ä¸€ä½å–„è§£äººæ„çš„æœ‹å‹ï¼Œç”¨æˆ¶å‰›åˆ†äº«äº†ä»Šå¤©ç™¼ç”Ÿçš„äº‹ã€‚è«‹çµ¦å‡º 1-2 å¥æœ‰å…±é³´çš„å›æ‡‰ï¼Œè¡¨ç¾å‡ºä½ çœŸçš„åœ¨è½ä¸¦ä¸”é—œå¿ƒã€‚ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œèªèª¿æº«æš–ã€‚\"\"\"\n",
        "        elif self.current_question_index == 2:\n",
        "            # é‡å°é¡è‰²é¸æ“‡çš„å›æ‡‰\n",
        "            system_prompt = \"\"\"ç”¨æˆ¶å‰›åˆ†äº«äº†ä»£è¡¨è‡ªå·±çš„é¡è‰²ã€‚è«‹å°ä»–å€‘çš„é¸æ“‡è¡¨é”èªåŒå’Œæ¬£è³ï¼Œå¯ä»¥ç°¡å–®æè¿°é€™å€‹é¡è‰²çµ¦ä½ çš„æ„Ÿè¦ºã€‚1-2 å¥å³å¯ï¼Œç¹é«”ä¸­æ–‡ï¼Œèªèª¿è®šç¾ä½†ä¸èª‡å¼µã€‚\"\"\"\n",
        "        elif self.current_question_index == 3:\n",
        "            # é‡å°æ¯”å–»çš„å›æ‡‰\n",
        "            system_prompt = \"\"\"ç”¨æˆ¶ç”¨äº†ä¸€å€‹å¾ˆæœ‰å‰µæ„çš„æ¯”å–»ä¾†å½¢å®¹è‡ªå·±ã€‚è«‹è¡¨é”å°é€™å€‹æ¯”å–»çš„æ¬£è³ï¼Œå¯ä»¥èªªèªªé€™å€‹æ¯”å–»çµ¦ä½ çš„æ„Ÿè¦ºã€‚1-2 å¥ï¼Œç¹é«”ä¸­æ–‡ï¼Œèªèª¿æ¬£è³ä¸”æº«æš–ã€‚\"\"\"\n",
        "        else:\n",
        "            # å…¶ä»–æƒ…æ³çš„é€šç”¨å›æ‡‰\n",
        "            system_prompt = \"\"\"ä½ æ˜¯ä¸€ä½æº«æš–çš„æœ‹å‹ï¼Œè«‹å°ç”¨æˆ¶çš„åˆ†äº«çµ¦å‡º 1-2 å¥æº«æš–çš„å›æ‡‰ã€‚ç”¨ç¹é«”ä¸­æ–‡ï¼Œèªèª¿è¦ªåˆ‡ã€‚\"\"\"\n",
        "\n",
        "        # è¨˜éŒ„ç”¨æˆ¶å›æ‡‰\n",
        "        self.user_responses.append(user_input)\n",
        "\n",
        "        # ç”Ÿæˆ AI çš„è·Ÿé€²å›æ‡‰\n",
        "        ai_response = self.get_ai_response(system_prompt, user_input)\n",
        "\n",
        "        # ç²å–ä¸‹ä¸€å€‹å•é¡Œ\n",
        "        next_question, is_finished = self.get_next_question()\n",
        "\n",
        "        # çµ„åˆå®Œæ•´å›æ‡‰\n",
        "        if is_finished:\n",
        "            full_response = ai_response + \"\\n\\n\" + next_question\n",
        "            return full_response, True\n",
        "        else:\n",
        "            full_response = ai_response + \"\\n\\n\" + next_question\n",
        "            return full_response, False\n",
        "\n",
        "    def generate_image_prompt(self):\n",
        "        \"\"\"å°‡ç”¨æˆ¶çš„æ‰€æœ‰å›æ‡‰è½‰æ›ç‚ºåœ–åƒç”Ÿæˆçš„ prompt\"\"\"\n",
        "        if len(self.user_responses) < 3:\n",
        "            return \"a beautiful portrait, warm lighting, artistic style\"\n",
        "\n",
        "        # ä½¿ç”¨ AI ä¾†åˆ†æç”¨æˆ¶å›æ‡‰ä¸¦ç”Ÿæˆåœ–åƒ prompt\n",
        "        system_prompt = \"\"\"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è¦–è¦ºæè¿°å°ˆå®¶ã€‚è«‹æ ¹æ“šç”¨æˆ¶åœ¨æ—¥è¨˜å°è©±ä¸­çš„å›æ‡‰ï¼Œå‰µé€ ä¸€å€‹è©³ç´°çš„è‹±æ–‡åœ–åƒæè¿° promptï¼Œç”¨æ–¼ AI åœ–åƒç”Ÿæˆã€‚\n",
        "\n",
        "        è¦æ±‚ï¼š\n",
        "        1. çµåˆç”¨æˆ¶çš„å¿ƒæƒ…ã€ç¶“æ­·ã€é¡è‰²åå¥½ã€è‡ªæˆ‘æ¯”å–»ç­‰å…ƒç´ \n",
        "        2. ç”Ÿæˆä¸€å€‹é©åˆäººåƒæˆ–æ„å¢ƒç•«çš„ prompt\n",
        "        3. åŒ…å«è—è¡“é¢¨æ ¼æè¿°ï¼ˆå¦‚ portrait, artistic, beautiful ç­‰ï¼‰\n",
        "        4. ä¿æŒæ­£é¢ç©æ¥µçš„æè¿°\n",
        "        5. åªè¼¸å‡ºè‹±æ–‡ promptï¼Œä¸è¦å…¶ä»–è§£é‡‹\n",
        "\n",
        "        ç”¨æˆ¶å›æ‡‰æ‘˜è¦ï¼š\n",
        "        \"\"\" + \"\\n\".join([f\"å•é¡Œ{i+1}: {resp}\" for i, resp in enumerate(self.user_responses)])\n",
        "\n",
        "        prompt = self.get_ai_response(system_prompt, \"è«‹ç”Ÿæˆåœ–åƒæè¿°\")\n",
        "\n",
        "        # æ·»åŠ ä¸€äº›æŠ€è¡“æ€§çš„å¢å¼·è©\n",
        "        enhanced_prompt = prompt + \", masterpiece, best quality, detailed, artistic lighting, beautiful composition\"\n",
        "\n",
        "        return enhanced_prompt\n",
        "\n",
        "# åˆå§‹åŒ– Agentï¼ˆå¦‚æœ AI å®¢æˆ¶ç«¯å¯ç”¨ï¼‰\n",
        "if 'ai_client' in globals():\n",
        "    diary_agent = DiaryAgent(ai_client)\n",
        "    print(\"ğŸ¤– AI æ—¥è¨˜ Agent åˆå§‹åŒ–å®Œæˆï¼\")\n",
        "else:\n",
        "    print(\"âŒ AI å®¢æˆ¶ç«¯æœªå°±ç·’ï¼Œè«‹å…ˆè¨­å®š API Key\")"
      ],
      "metadata": {
        "id": "Lfq31PS-Y6Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Cell 6: åœ–åƒç”Ÿæˆå‡½æ•¸ ==========\n",
        "def generate_diary_image(prompt, negative_prompt=\"blurry, bad anatomy, low quality, worst quality\",\n",
        "                        height=512, width=512, steps=25):\n",
        "    \"\"\"æ ¹æ“šæ—¥è¨˜å…§å®¹ç”Ÿæˆå€‹äººç•«åƒ\"\"\"\n",
        "    try:\n",
        "        # æ¸…ç†è¨˜æ†¶é«”\n",
        "        gc.collect()\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # è¨­å®šéš¨æ©Ÿç¨®å­\n",
        "        seed = random.randint(0, 2**32 - 1)\n",
        "        generator = torch.Generator(device).manual_seed(seed)\n",
        "\n",
        "        # ç”Ÿæˆåœ–åƒ\n",
        "        with torch.no_grad():\n",
        "            result = pipe(\n",
        "                prompt=prompt,\n",
        "                negative_prompt=negative_prompt,\n",
        "                height=height,\n",
        "                width=width,\n",
        "                num_inference_steps=steps,\n",
        "                guidance_scale=7.5,\n",
        "                generator=generator\n",
        "            )\n",
        "\n",
        "        return result.images[0], f\"âœ… ç”ŸæˆæˆåŠŸï¼ä½¿ç”¨ seed: {seed}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ ç”Ÿæˆå¤±æ•—: {str(e)}\""
      ],
      "metadata": {
        "id": "Wl2q16nyZFSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Cell 7: å‰µå»º Gradio ç•Œé¢ ==========\n",
        "def chat_with_agent(user_input, chat_history):\n",
        "    \"\"\"è™•ç†èˆ‡ Agent çš„å°è©±\"\"\"\n",
        "    if not user_input or not user_input.strip():\n",
        "        return chat_history, \"\"\n",
        "\n",
        "    # æª¢æŸ¥ diary_agent æ˜¯å¦å­˜åœ¨\n",
        "    if 'diary_agent' not in globals():\n",
        "        chat_history.append([user_input, \"âŒ AI Agent æœªåˆå§‹åŒ–ï¼Œè«‹å…ˆè¨­å®š API Key\"])\n",
        "        return chat_history, \"\"\n",
        "\n",
        "    try:\n",
        "        # è™•ç†ç”¨æˆ¶è¼¸å…¥\n",
        "        ai_response, is_finished = diary_agent.process_user_response(user_input)\n",
        "\n",
        "        # æ›´æ–°å°è©±æ­·å²\n",
        "        chat_history.append([user_input, ai_response])\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ å°è©±è™•ç†å¤±æ•—: {str(e)}\"\n",
        "        chat_history.append([user_input, error_msg])\n",
        "\n",
        "    return chat_history, \"\"\n",
        "\n",
        "def generate_final_image():\n",
        "    \"\"\"ç”Ÿæˆæœ€çµ‚çš„å€‹äººç•«åƒ\"\"\"\n",
        "    # æª¢æŸ¥å¿…è¦çµ„ä»¶\n",
        "    if 'diary_agent' not in globals():\n",
        "        return None, \"âŒ AI Agent æœªåˆå§‹åŒ–\"\n",
        "\n",
        "    if 'pipe' not in globals():\n",
        "        return None, \"âŒ Stable Diffusion æ¨¡å‹æœªè¼‰å…¥\"\n",
        "\n",
        "    if len(diary_agent.user_responses) < 3:\n",
        "        return None, \"è«‹å…ˆå®Œæˆè‡³å°‘ 3 å€‹å•é¡Œçš„å°è©± ğŸ˜Š\"\n",
        "\n",
        "    try:\n",
        "        # ç”Ÿæˆåœ–åƒ prompt\n",
        "        image_prompt = diary_agent.generate_image_prompt()\n",
        "\n",
        "        # ç”Ÿæˆåœ–åƒ\n",
        "        image, status = generate_diary_image(image_prompt)\n",
        "\n",
        "        return image, f\"ğŸ¨ æ ¹æ“šä½ çš„åˆ†äº«ç”Ÿæˆçš„ç•«åƒ\\n\\nä½¿ç”¨çš„æè¿°ï¼š{image_prompt}\\n\\n{status}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ åœ–åƒç”Ÿæˆå¤±æ•—: {str(e)}\"\n",
        "\n",
        "def reset_conversation():\n",
        "    \"\"\"é‡ç½®å°è©±\"\"\"\n",
        "    global diary_agent\n",
        "\n",
        "    # æª¢æŸ¥ ai_client æ˜¯å¦å­˜åœ¨\n",
        "    if 'ai_client' not in globals():\n",
        "        return [[\"\", \"âŒ è«‹å…ˆè¨­å®š API Key\"]], None, \"è«‹å…ˆè¨­å®š AI API\"\n",
        "\n",
        "    try:\n",
        "        diary_agent = DiaryAgent(ai_client)\n",
        "\n",
        "        # è¿”å›åˆå§‹å•é¡Œ\n",
        "        first_question, _ = diary_agent.get_next_question()\n",
        "        initial_chat = [[\"\", first_question]]\n",
        "\n",
        "        return initial_chat, None, \"é–‹å§‹æ–°çš„æ—¥è¨˜å°è©± âœ¨\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return [[\"\", f\"âŒ åˆå§‹åŒ–å¤±æ•—: {str(e)}\"]], None, \"åˆå§‹åŒ–å¤±æ•—\"\n",
        "\n",
        "# è‡ªå®šç¾© CSS\n",
        "custom_css = \"\"\"\n",
        ".gradio-container {\n",
        "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "    font-family: 'Arial', sans-serif;\n",
        "}\n",
        ".chat-container {\n",
        "    background: rgba(255,255,255,0.1);\n",
        "    border-radius: 15px;\n",
        "    padding: 20px;\n",
        "    backdrop-filter: blur(10px);\n",
        "}\n",
        ".gr-button {\n",
        "    background: linear-gradient(45deg, #FF6B6B, #4ECDC4);\n",
        "    border: none;\n",
        "    color: white;\n",
        "    font-weight: bold;\n",
        "    border-radius: 10px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# å‰µå»ºç•Œé¢\n",
        "with gr.Blocks(css=custom_css, title=\"AI æ—¥è¨˜ç¹ªå¸«\") as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸ¨ AI æ—¥è¨˜ç¹ªå¸«\n",
        "    ## ğŸ“– è®“ AI é™ªä½ å¯«æ—¥è¨˜ï¼Œå†ç‚ºä½ ç•«å‡ºã€Œæˆ‘çœ¼ä¸­çš„ä½ ã€\n",
        "\n",
        "    **âœ¨ é«”é©—æµç¨‹ï¼š**\n",
        "    1. ğŸ—£ï¸ èˆ‡ AI é€²è¡Œæº«æš–çš„æ—¥è¨˜å°è©± (5å€‹å•é¡Œ)\n",
        "    2. ğŸ¯ AI åˆ†æä½ çš„å›æ‡‰ï¼Œç†è§£ä»Šå¤©çš„ä½ \n",
        "    3. ğŸ¨ è‡ªå‹•ç”Ÿæˆå°ˆå±¬çš„å€‹äººç•«åƒ\n",
        "    4. ğŸ’• ç²å¾—ç¨ä¸€ç„¡äºŒçš„ã€Œæˆ‘çœ¼ä¸­çš„ä½ ã€\n",
        "    \"\"\")\n",
        "\n",
        "    # æª¢æŸ¥æ¨¡å‹ç‹€æ…‹\n",
        "    model_status = \"\"\n",
        "    if 'pipe' in globals() and pipe is not None:\n",
        "        model_status = f\"âœ… **Stable Diffusion å·²å°±ç·’** (è¨­å‚™: {device.upper()})\"\n",
        "    else:\n",
        "        model_status = \"âš ï¸ **Stable Diffusion æ¨¡å‹æœªè¼‰å…¥ï¼Œè«‹å…ˆåŸ·è¡Œæ¨¡å‹è¼‰å…¥ç¨‹å¼ç¢¼**\"\n",
        "\n",
        "    ai_status = \"\"\n",
        "    if 'ai_client' in globals() and ai_client is not None:\n",
        "        ai_status = \" | âœ… **AI Agent å·²å°±ç·’**\"\n",
        "    else:\n",
        "        ai_status = \" | âŒ **AI Agent æœªå°±ç·’ï¼Œè«‹è¨­å®š API Key**\"\n",
        "\n",
        "    gr.Markdown(model_status + ai_status)\n",
        "\n",
        "    with gr.Row():\n",
        "        # å·¦å´ï¼šå°è©±å€\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### ğŸ’­ æ—¥è¨˜å°è©±å€\")\n",
        "\n",
        "            # å®‰å…¨çš„åˆå§‹åŒ–å°è©±\n",
        "            try:\n",
        "                if 'diary_agent' in globals() and diary_agent is not None:\n",
        "                    first_question, _ = diary_agent.get_next_question()\n",
        "                    initial_chat = [[\"\", first_question]]\n",
        "                else:\n",
        "                    initial_chat = [[\"\", \"è«‹å…ˆè¨­å®š API Key ä¸¦åˆå§‹åŒ– AI Agent ğŸ¤–\"]]\n",
        "            except Exception as e:\n",
        "                initial_chat = [[\"\", f\"åˆå§‹åŒ–éŒ¯èª¤: {str(e)} è«‹é‡æ–°åŸ·è¡Œç›¸é—œç¨‹å¼ç¢¼\"]]\n",
        "\n",
        "            chatbot = gr.Chatbot(\n",
        "                value=initial_chat,\n",
        "                label=\"èˆ‡ AI æ—¥è¨˜åŠ©æ‰‹å°è©±\",\n",
        "                height=400,\n",
        "                elem_classes=[\"chat-container\"]\n",
        "            )\n",
        "\n",
        "            user_input = gr.Textbox(\n",
        "                label=\"ğŸ’¬ ä½ çš„å›æ‡‰\",\n",
        "                placeholder=\"åœ¨é€™è£¡åˆ†äº«ä½ çš„æƒ³æ³•...\",\n",
        "                lines=2\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                send_btn = gr.Button(\"ğŸ“¤ ç™¼é€\", variant=\"primary\")\n",
        "                reset_btn = gr.Button(\"ğŸ”„ é‡æ–°é–‹å§‹\", variant=\"secondary\")\n",
        "\n",
        "        # å³å´ï¼šåœ–åƒç”Ÿæˆå€\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### ğŸ–¼ï¸ æˆ‘çœ¼ä¸­çš„ä½ \")\n",
        "\n",
        "            generated_image = gr.Image(\n",
        "                label=\"AI ç‚ºä½ å‰µä½œçš„ç•«åƒ\",\n",
        "                height=400\n",
        "            )\n",
        "\n",
        "            generate_btn = gr.Button(\n",
        "                \"ğŸ¨ ç”Ÿæˆæˆ‘çš„ç•«åƒ\",\n",
        "                variant=\"primary\",\n",
        "                size=\"lg\"\n",
        "            )\n",
        "\n",
        "            image_status = gr.Textbox(\n",
        "                label=\"ç”Ÿæˆç‹€æ…‹\",\n",
        "                value=\"å®Œæˆå°è©±å¾Œï¼Œé»æ“Šä¸Šæ–¹æŒ‰éˆ•ç”Ÿæˆå°ˆå±¬ç•«åƒ âœ¨\",\n",
        "                interactive=False,\n",
        "                lines=4\n",
        "            )\n",
        "\n",
        "    # ========== äº‹ä»¶ç¶å®š ==========\n",
        "\n",
        "    # ç™¼é€è¨Šæ¯\n",
        "    send_btn.click(\n",
        "        fn=chat_with_agent,\n",
        "        inputs=[user_input, chatbot],\n",
        "        outputs=[chatbot, user_input]\n",
        "    )\n",
        "\n",
        "    # æŒ‰ Enter ç™¼é€\n",
        "    user_input.submit(\n",
        "        fn=chat_with_agent,\n",
        "        inputs=[user_input, chatbot],\n",
        "        outputs=[chatbot, user_input]\n",
        "    )\n",
        "\n",
        "    # ç”Ÿæˆåœ–åƒ\n",
        "    generate_btn.click(\n",
        "        fn=generate_final_image,\n",
        "        outputs=[generated_image, image_status]\n",
        "    )\n",
        "\n",
        "    # é‡ç½®å°è©±\n",
        "    reset_btn.click(\n",
        "        fn=reset_conversation,\n",
        "        outputs=[chatbot, generated_image, image_status]\n",
        "    )\n",
        "\n",
        "    # ä½¿ç”¨èªªæ˜\n",
        "    gr.Markdown(\"\"\"\n",
        "    ### ğŸ“‹ ä½¿ç”¨æŒ‡å—\n",
        "\n",
        "    **ğŸ¯ å®Œæ•´é«”é©—æ­¥é©Ÿï¼š**\n",
        "    1. **é–‹å§‹å°è©±**ï¼šAI æœƒå•ä½  5 å€‹æº«æš–çš„å•é¡Œ\n",
        "    2. **çœŸèª åˆ†äº«**ï¼šåˆ†äº«ä½ ä»Šå¤©çš„å¿ƒæƒ…ã€ç¶“æ­·ã€æƒ³æ³•\n",
        "    3. **ç²å¾—ç•«åƒ**ï¼šå®Œæˆå°è©±å¾Œé»æ“Šã€Œç”Ÿæˆæˆ‘çš„ç•«åƒã€\n",
        "    4. **æ¬£è³ä½œå“**ï¼šAI æœƒæ ¹æ“šä½ çš„åˆ†äº«å‰µä½œç¨ç‰¹ç•«åƒ\n",
        "\n",
        "    **ğŸ’¡ åˆ†äº«æŠ€å·§ï¼š**\n",
        "    - çœŸå¯¦è¡¨é”ä½ çš„æ„Ÿå—ï¼Œä¸ç”¨å®Œç¾\n",
        "    - å¯ä»¥åˆ†äº«å…·é«”çš„ç´°ç¯€å’Œæƒ³æ³•\n",
        "    - é¡è‰²å’Œæ¯”å–»å¯ä»¥å¾ˆæœ‰å‰µæ„\n",
        "    - è¶ŠçœŸèª åˆ†äº«ï¼Œç•«åƒè¶Šè²¼è¿‘ä½ çš„å…§å¿ƒ\n",
        "\n",
        "    **ğŸ”„ æƒ³é‡æ–°é«”é©—ï¼Ÿ**\n",
        "    é»æ“Šã€Œé‡æ–°é–‹å§‹ã€å°±èƒ½é–‹å•Ÿæ–°çš„æ—¥è¨˜å°è©±ï¼\n",
        "    \"\"\")\n",
        "\n",
        "print(\"ğŸ¨ AI æ—¥è¨˜ç¹ªå¸«ç•Œé¢å‰µå»ºå®Œæˆï¼\")\n"
      ],
      "metadata": {
        "id": "M-s8hTVLcYeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Cell 8: å•Ÿå‹•æ‡‰ç”¨ ==========\n",
        "# åŸ·è¡Œé€™å€‹ cell ä¾†å•Ÿå‹•å®Œæ•´çš„æ—¥è¨˜ç¹ªå¸«ç³»çµ±\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸš€ æ­£åœ¨å•Ÿå‹• AI æ—¥è¨˜ç¹ªå¸«...\")\n",
        "    demo.launch(\n",
        "        share=True,\n",
        "        debug=True,\n",
        "        height=900,\n",
        "        show_error=True\n",
        "    )"
      ],
      "metadata": {
        "id": "05a6Df84ceYX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}